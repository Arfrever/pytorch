name: inductor

on:
  push:
    branches:
      - master
    tags:
      - ciflow/inductor/*
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}
  cancel-in-progress: true

jobs:
  pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12-inductor-build:
    name: cuda11.6-py3.8-clang12
    uses: ./.github/workflows/_linux-build.yml
    with:
      build-environment: linux-jammy-cuda11.6-cudnn8-py3.8-clang12
      docker-image-name: pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12
      cuda-arch-list: 8.6
      test-matrix: |
        { include: [
          { config: "inductor", shard: 1, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 2, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 3, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 4, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 5, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 6, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 7, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 8, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 9, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 10, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 11, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
          { config: "inductor", shard: 12, num_shards: 12, runner: "linux.g5.4xlarge.nvidia.gpu" },
        ]}

  pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12-inductor-test:
    name: cuda11.6-py3.8-clang12
    uses: ./.github/workflows/_linux-test.yml
    needs: pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12-inductor-build
    with:
      build-environment: linux-bionic-cuda11.6-py3.8-clang12
      docker-image: ${{ needs.pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12-inductor-build.outputs.docker-image }}
      test-matrix: ${{ needs.pytorch-linux-jammy-cuda11.6-cudnn8-py3.8-clang12-inductor-build.outputs.test-matrix }}
